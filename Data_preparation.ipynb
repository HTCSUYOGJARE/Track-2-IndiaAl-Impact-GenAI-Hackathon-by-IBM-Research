{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":107251,"databundleVersionId":13166028,"sourceType":"competition"},{"sourceId":12995331,"sourceType":"datasetVersion","datasetId":8225868}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.experimental import enable_hist_gradient_boosting  # noqa\nfrom sklearn.ensemble import HistGradientBoostingRegressor, RandomForestClassifier\n\n# --------------------------\n# 1. Load data\n# --------------------------\nmeta = pd.read_csv(\"/kaggle/input/short-term-load-forecasting/metadata.csv\")\ntrain = pd.read_csv(\"/kaggle/input/short-term-load-forecasting/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/short-term-load-forecasting/test.csv\")\n\n# remove duplicates from metadata\nmeta = meta.drop_duplicates(subset=[\"building_id\"]).reset_index(drop=True)\n\n# --------------------------\n# 2. Imputation for metadata\n# --------------------------\ndef impute_metadata(meta):\n    df = meta.copy()\n\n    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n    cat_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n\n    # Impute numeric (example: area_in_sqft) using HistGradientBoosting\n    for col in [\"area_in_sqft\"]:\n        if col in df.columns and df[col].isnull().sum() > 0:\n            not_null = df[df[col].notnull()]\n            null = df[df[col].isnull()]\n            features = [c for c in num_cols if c != col]\n\n            if not_null.shape[0] > 5:\n                hgb = HistGradientBoostingRegressor(random_state=42)\n                hgb.fit(not_null[features], not_null[col])\n                df.loc[df[col].isnull(), col] = hgb.predict(null[features])\n            else:\n                df[col] = df[col].fillna(df[col].median())\n\n    # Impute categorical/binary (example: inverter) with RandomForestClassifier\n    for col in [\"inverter\"]:\n        if col in df.columns and df[col].isnull().sum() > 0:\n            not_null = df[df[col].notnull()]\n            null = df[df[col].isnull()]\n            features = [c for c in num_cols if c != col]\n\n            if not_null.shape[0] > 5:\n                rf = RandomForestClassifier(n_estimators=100, random_state=42)\n                rf.fit(not_null[features], not_null[col].astype(int))\n                df.loc[df[col].isnull(), col] = rf.predict(null[features])\n            else:\n                df[col] = df[col].fillna(df[col].mode()[0])\n\n    # Fallback: median for any remaining numeric NaNs\n    df[num_cols] = df[num_cols].fillna(df[num_cols].median())\n    return df\n\nmeta = impute_metadata(meta)\n\n# --------------------------\n# 3. Feature Engineering\n# --------------------------\ndef feature_engineering(data, is_train=True):\n    df = data.copy()\n\n    # timestamp features\n    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n    df[\"hour\"] = df[\"timestamp\"].dt.hour\n    df[\"dayofweek\"] = df[\"timestamp\"].dt.dayofweek\n    df[\"month\"] = df[\"timestamp\"].dt.month\n    df[\"is_weekend\"] = df[\"dayofweek\"].isin([5,6]).astype(int)\n\n    # lags\n    df = df.sort_values([\"building_id\", \"timestamp\"])\n    if \"meter_reading\" in df.columns:  # only in train\n        df[\"meter_lag1\"] = df.groupby(\"building_id\")[\"meter_reading\"].shift(1)\n        df[\"meter_lag24\"] = df.groupby(\"building_id\")[\"meter_reading\"].shift(24)\n        df[\"meter_lag168\"] = df.groupby(\"building_id\")[\"meter_reading\"].shift(168)\n\n        # rolling stats\n        df[\"meter_roll_mean_24h\"] = df.groupby(\"building_id\")[\"meter_reading\"].transform(lambda x: x.rolling(24, min_periods=1).mean())\n        df[\"meter_roll_std_24h\"] = df.groupby(\"building_id\")[\"meter_reading\"].transform(lambda x: x.rolling(24, min_periods=1).std())\n        df[\"meter_roll_mean_7d\"] = df.groupby(\"building_id\")[\"meter_reading\"].transform(lambda x: x.rolling(24*7, min_periods=1).mean())\n\n    # normalized static features\n    if \"area_in_sqft\" in df.columns and \"rooms\" in df.columns:\n        df[\"area_per_room\"] = df[\"area_in_sqft\"] / df[\"rooms\"].replace(0, np.nan)\n        df[\"people_per_room\"] = df[\"no_of_people\"] / df[\"rooms\"].replace(0, np.nan)\n        df[\"people_per_sqft\"] = df[\"no_of_people\"] / df[\"area_in_sqft\"].replace(0, np.nan)\n\n        df[\"lights_per_room\"] = df[\"lights\"] / df[\"rooms\"].replace(0, np.nan)\n        df[\"fans_per_room\"] = df[\"ceiling_fans\"] / df[\"rooms\"].replace(0, np.nan)\n        df[\"ac_per_room\"] = df[\"air_conditioners\"] / df[\"rooms\"].replace(0, np.nan)\n        df[\"fridge_per_person\"] = df[\"fridge\"] / df[\"no_of_people\"].replace(0, np.nan)\n\n        df[\"appliance_density\"] = (\n            df[\"lights\"] + df[\"ceiling_fans\"] + df[\"air_coolers\"] +\n            df[\"air_conditioners\"] + df[\"fridge\"] + df[\"tv\"] +\n            df[\"water_heaters\"] + df[\"washing_machine\"] +\n            df[\"mixer\"] + df[\"iron\"] + df[\"micro_wave\"]\n        ) / df[\"area_in_sqft\"].replace(0, np.nan)\n\n    # interaction features\n    df[\"has_ac\"] = (df[\"air_conditioners\"] > 0).astype(int)\n    df[\"has_fridge\"] = (df[\"fridge\"] > 0).astype(int)\n    df[\"has_inverter\"] = (df[\"inverter\"] > 0).astype(int)\n\n    df[\"electricity_load_score\"] = (\n        2 * df[\"air_conditioners\"] +\n        1.5 * df[\"water_heaters\"] +\n        1 * df[\"fridge\"] +\n        0.5 * df[\"lights\"] +\n        0.3 * df[\"ceiling_fans\"]\n    )\n\n    # region-based features\n    if \"region\" in df.columns:\n        region_stats = df.groupby(\"region\")[\"area_in_sqft\"].median().rename(\"region_median_area\")\n        df = df.merge(region_stats, on=\"region\", how=\"left\")\n        df[\"deviation_from_region_area\"] = df[\"area_in_sqft\"] - df[\"region_median_area\"]\n\n    # building-based stats (only train has meter_reading)\n    if \"meter_reading\" in df.columns:\n        bldg_stats = df.groupby(\"building_id\")[\"meter_reading\"].agg([\"mean\",\"std\",\"max\"])\n        bldg_stats[\"peak_to_mean_ratio\"] = bldg_stats[\"max\"] / (bldg_stats[\"mean\"]+1e-6)\n        bldg_stats = bldg_stats.add_prefix(\"bldg_\").reset_index()\n        df = df.merge(bldg_stats, on=\"building_id\", how=\"left\")\n\n    # missingness indicators\n    df[\"is_area_missing\"] = df[\"area_in_sqft\"].isnull().astype(int)\n    df[\"is_inverter_missing\"] = df[\"inverter\"].isnull().astype(int)\n\n    return df\n\n# --------------------------\n# 4. Apply transformations\n# --------------------------\ntrain = train.merge(meta, on=\"building_id\", how=\"left\")\ntest  = test.merge(meta, on=\"building_id\", how=\"left\")\n\nfinal_train = feature_engineering(train, is_train=True)\nfinal_test  = feature_engineering(test, is_train=False)\n\n# --------------------------\n# 5. Save results\n# --------------------------\nfinal_train.to_csv(\"/kaggle/working/final_train.csv\", index=False)\nfinal_test.to_csv(\"/kaggle/working/final_test.csv\", index=False)\n\n\nprint(\"✅ Final train shape:\", final_train.shape)\nprint(\"✅ Final test shape :\", final_test.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T06:34:19.574899Z","iopub.execute_input":"2025-09-13T06:34:19.575339Z","iopub.status.idle":"2025-09-13T06:36:37.782839Z","shell.execute_reply.started":"2025-09-13T06:34:19.575309Z","shell.execute_reply":"2025-09-13T06:36:37.781498Z"}},"outputs":[{"name":"stdout","text":"✅ Final train shape: (2582976, 51)\n✅ Final test shape : (676800, 52)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"final_train = pd.read_csv(\"/kaggle/working/final_train.csv\")\nfinal_test = pd.read_csv(\"/kaggle/working/final_test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T06:38:13.318787Z","iopub.execute_input":"2025-09-13T06:38:13.319597Z","iopub.status.idle":"2025-09-13T06:38:35.938092Z","shell.execute_reply.started":"2025-09-13T06:38:13.319559Z","shell.execute_reply":"2025-09-13T06:38:35.937039Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T06:39:53.156053Z","iopub.execute_input":"2025-09-13T06:39:53.156404Z","iopub.status.idle":"2025-09-13T06:39:53.982302Z","shell.execute_reply.started":"2025-09-13T06:39:53.156376Z","shell.execute_reply":"2025-09-13T06:39:53.981363Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"building_id                       0\nwindow_id                         0\ntimestamp                         0\nmeter_reading                     0\nrole                              0\nregion                            0\nrooms                             0\nno_of_people                      0\narea_in_sqft                      0\ninverter                          0\nlights                            0\nceiling_fans                      0\nair_coolers                       0\nair_conditioners                  0\nfridge                            0\ntv                                0\nwater_heaters                     0\nwashing_machine                   0\nmixer                             0\niron                              0\nmicro_wave                        0\nhour                              0\ndayofweek                         0\nmonth                             0\nis_weekend                        0\nmeter_lag1                       91\nmeter_lag24                    2184\nmeter_lag168                  15288\nmeter_roll_mean_24h               0\nmeter_roll_std_24h               91\nmeter_roll_mean_7d                0\narea_per_room                 10176\npeople_per_room               10176\npeople_per_sqft                   0\nlights_per_room               10176\nfans_per_room                 10176\nac_per_room                   10176\nfridge_per_person                 0\nappliance_density                 0\nhas_ac                            0\nhas_fridge                        0\nhas_inverter                      0\nelectricity_load_score            0\nregion_median_area                0\ndeviation_from_region_area        0\nbldg_mean                         0\nbldg_std                          0\nbldg_max                          0\nbldg_peak_to_mean_ratio           0\nis_area_missing                   0\nis_inverter_missing               0\ndtype: int64"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}